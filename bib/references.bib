@article{Krizhevsky2012ImageNet,
  abstract = {This research describes a deep convolutional neural network (CNN) architecture for large-scale classification of image problems. It illustrates the usefulness of deep learning for image categorization, especially on the difficult ImageNet dataset. The proposed CNN architecture incorporates many convolutional and fully connected layers that use techniques such as ReLU activation, data augmentation, dropout, and local response normalization to improve generalization and reduce overfitting. The ImageNet dataset is used in the study, which contains millions of tagged photos from various item categories. The new technique is quantitatively evaluated by comparing AlexNet's performance to earlier algorithms, demonstrating a significant drop in error rate.},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  journal = {Communications of the ACM},
  keywords = {type: deep learning, image classification, ImageNet, convolutional neural networks, deep neural networks},
  volume = {60},
  number = {6},
  pages = {84-90},
  year = {2017},
  doi = {10.1145/3065386}
}

@article{Mnih2013PlayingAtari,
  abstract = {In this research, a brand-new deep reinforcement learning method for playing Atari games is presented. It demonstrates how an artificial intelligence can learn to play a variety of Atari 2600 games just by looking at them. With the help of the method, which combines deep neural networks with Q-learning, the agent may create sophisticated tactics and improve its performance over time. To interpret game pictures and determine action values, the system uses a deep convolutional neural network. The agent gains experience by making mistakes and is rewarded according to how well it plays the game. The evaluation quantitatively quantifies the agent's performance advantage over conventional approaches using game scores.Paper DOI: The DOI for the paper is not provided in the given information.},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  title = {Playing Atari with Deep Reinforcement Learning},
  journal = {arXiv preprint arXiv:1312.5602},
  keywords = {type: deep reinforcement learning, Atari, Q-learning, deep Q-networks, reinforcement learning},
  year = {2013},
  doi = {10.48550/arXiv.1312.5602}
}


@article{LeCun2015DeepLearning,
  abstract = {This study presents the idea of deep learning, which instructs neural networks to pick up hierarchical data representations. It explores the advantages of generative models and unsupervised learning while emphasizing the significance of depth in neural networks. It offers a thorough review of deep learning techniques, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs), without concentrating on a single implementation or approach. Deep learning may be used with a variety of data kinds, including pictures, text, audio, and numerical data, despite the fact that data properties are not expressly addressed. The paper acts as a review and introduction to deep learning, displaying its potential and emphasizing essential components of the discipline, rather than providing a particular evaluation or comparison.},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  title = {Deep Learning},
  journal = {Nature},
  keywords = {type: deep learning, artificial neural networks, machine learning, deep neural networks, deep representation learning},
  volume = {521},
  number = {7553},
  pages = {436-444},
  year = {2015},
  doi = {10.1038/nature14539}
}


@article{Goodfellow2014Generative,
abstract = {Generative Adversarial Nets (GANs), a novel generative model that use a game-theoretic methodology to learn and produce realistic data, are introduced in this study. A generator and a discriminator are the two neural networks that make up GANs. They play a minimax game in which the generator generates data that resembles real data and the discriminator distinguishes between produced and real data. The adversarial loss, a brand-new loss function that controls the output of the generator, is also presented in this study. Deep neural networks were used by the authors to develop the GAN model in Python, and it was trained using datasets including MNIST, CIFAR-10, and LSUN. The model's performance was assessed qualitatively by visual examination and compared with other algorithms in terms of time, accuracy, and other metrics like Inception Score and Frechet Inception Distance.},
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
title = {Generative Adversarial Nets},
journal = {arXiv preprint arXiv:1406.2661},
keywords = {type: generative adversarial networks, deep learning, unsupervised learning, generative models, adversarial training},
year = {2014},
url = {https://arxiv.org/abs/1406.2661}
}

@article{Taigman2014DeepFace,
abstract = {This study introduces DeepFace, a deep learning model built to handle face verification tasks at a human-level. With the help of several layers, the deep neural network architecture used by DeepFace builds hierarchical representations of face characteristics. The algorithm extracts discriminative features to precisely verify faces after being trained on a sizable dataset of labeled face photos. The dataset includes a variety of positions, lighting, and facial expressions to accurately represent real-world situations. Utilizing quantitative metrics, the review compares DeepFace's performance time, input data size, and accuracy against those of prior methods. A controlled user research is also carried out to evaluate DeepFace's efficacy.},
author = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
title = {DeepFace: Closing the Gap to Human-Level Performance in Face Verification},
journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
keywords = {type: ace verification, deep learning, facial recognition, convolutional neural networks, computer vision},
year = {2014},
pages = {1701-1708},
doi = {10.1109/CVPR.2014.220}
}

@article{Radford2016Unsupervised,
abstract = {As a method of unsupervised representation learning, deep convolutional generative adversarial networks (DCGANs) are introduced in this study. It illustrates that DCGANs are capable of learning a hierarchy of representations without direct instruction and generating pictures of excellent quality. The generator and discriminator of the authors' DCGAN model are both implemented using a deep convolutional neural network architecture. A sizable collection of pictures from the ImageNet dataset, which includes more than 1.2 million images in 1,000 categories, is used for training. To determine the perceived picture quality, the DCGAN model is evaluated using a mix of quantitative measures, visual inspection, and a user research.},
author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
title = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
keywords = {type: unsupervised learning, deep learning, generative adversarial networks, convolutional neural networks, representation learning},
journal = {Association for Computing Machinery},
volume = {60},
number = {6},
pages = {86-94},
year = {2016},
doi = {10.1145/2969033.2969125}
}


@article{He2016Deep,
abstract = {ResNet, a novel architecture for deep convolutional neural networks (CNNs) training in image recognition, is introduced in the study. The authors find that CNNs with hundreds of layers outperform shallower networks with fewer parameters by adding residual learning. In order to solve the disappearing gradient problem, they suggest a network block called the residual block, which enables gradients to travel back to prior levels. On the ImageNet dataset, the authors trained and assessed ResNet, yielding cutting-edge results in picture categorization. They looked examined how accuracy and computing efficiency were impacted by network depth. ImageNet, a dataset with a broad collection of more than a million pictures arranged into a thousand classifications, was used. The accuracy and computational efficiency of ResNet were compared to those of different CNN designs using quantitative approaches, and an ablation research was carried out to look at the effects of residual blocks and network depth on model performance.},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
keywords = {type: image recognition, deep learning, convolutional neural networks, residual networks, deep residual learning},
pages = {770-778},
year = {2016},
doi = {10.1109/CVPR.2016.90}
}


@article{Bengio2013Representation,
abstract = {This in-depth study of representation learning focuses on techniques for autonomously learning useful representations from data. Unsupervised, supervised, and semi-supervised learning are all topics covered by the authors' exploration of various methodologies. They place emphasis on the value of representation learning in dealing with challenging machine learning issues. The research largely assesses current approaches while presenting novel viewpoints on representation learning. It provides an overview of many techniques and their underlying ideas rather than concentrating on particular implementations or methodologies. Despite the fact that data features are not explicitly covered, the work focuses more on the general idea of representation learning and its ramifications than it does on a specific dataset. The authors of this study evaluate representation learning using a qualitative approach, reviewing and analyzing earlier algorithms and techniques. They contrast these methods based on their fundamental ideas, practicality, and future uses.},
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
title = {Representation Learning: A Review and New Perspectives},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {type: representation learning, deep learning, unsupervised learning, deep neural networks, feature learning},
volume = {35},
number = {8},
pages = {1798-1828},
year = {2013},
doi = {10.1109/TPAMI.2013.50}
}

@article{Simonyan2014VeryDeep,
abstract = {The research proposes Very Deep Convolutional Networks (VGG), a deep learning architecture for massive picture recognition. The authors concentrate on creating and assessing convolutional neural networks that are deeper and deeper, leading to better picture categorization performance. VGG comprises of several layers with tiny convolutional filters and a sizable number of trainable parameters. The authors describe the network designs and training methods used to reach cutting-edge results. The study makes use of huge picture databases, like ImageNet, which include complex and varied images belonging to a variety of categories. The evaluation is quantitative, contrasting the precision of VGG networks with earlier algorithms, and trials show the higher performance of VGG on picture classification tasks.},
author = {Simonyan, Karen and Zisserman, Andrew},
title = {VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION},
keywords = {type: deep learning, image recognition, convolutional neural networks, large-scale image recognition, deep neural networks},
journal = {arXiv preprint},
volume = {1409.1556},
year = {2014},
doi = {10.48550/arXiv.1409.1556}
}

@article{Deng2009ImageNet,
  abstract = {The publication presents ImageNet, a large picture database with millions of tagged photos arranged in hierarchical categories. It serves as a benchmark dataset for massively scalable object and picture recognition. The writers gathered and tagged a sizable number of online photos, classifying them according to WordNet. A fine-grained dataset comprising several item categories was produced by human annotators assigning labels. For both qualitative and quantitative analysis, ImageNet provides a vast database of pictures. The authors compare it to earlier algorithms, noting its advantages in terms of performance time, accuracy, and dataset size, and show how it improves computer vision models for a range of picture identification applications.},
  author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  title = {ImageNet: A large-scale hierarchical image database},
  journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  keywords = {type: image database, large-scale dataset, computer vision, image classification, hierarchical structure},
  pages = {248-255},
  year = {2009},
  doi = {10.1109/CVPR.2009.5206848}
}



